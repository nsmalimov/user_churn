Задание:
Наша компания занимается рекламой и у нас есть данные о том как пользователи смотрят телепередачи в интернете.
Каждая сессия пользователя записывается отдельной строкой в БД. Если пользователь отключился или переключил канал, то появляется новая строка.
Вам нужно обучить модель, которая будет предсказывать вероятность того, что пришедший пользователь посмотрит рекламный блок целиком и не переключится (на самом деле нам интересна вероятность просмотра каждого отдельного ролика, но это выходит за рамки теста).

Мы даем два датасета:
1. Логи телесмотрения одного телеканала ( https://drive.google.com/file/d/0B4KsV5IwPYeGMmVDVHFMNUtlRXM/view?usp=sharing ) 2. Оперативные плейлисты выхода рекламных роликов (в какое время были выпуски рекламы в первом датасете) ( https://drive.google.com/file/d/0B4KsV5IwPYeGeXJMWnRnVE9QVEk/view?usp=sharing )
Пространство дат обоих датасетов должно приблизительно совпадать. Если не совпадает, то можно сгенерировать похожее распределение.
В результате нужно предоставить ipython ноутбук с выполненным заданием и защитить его в офисе или по скайпу.
Желательно обосновать выбор используемого метода.

У нас таких данных сотни гигабайт. Как будете обучаться на таком объеме?
Владеете ли вы методами понижения размерности данных? Применимы ли эти методы к этой задаче?
Какова точность прогноза на представленном датасете?